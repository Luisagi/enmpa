---
title: "enmpa: Ecological Niche Modeling for Presence-absence Data"
author: "Luis F. Arias-Giraldo, Marlon E. Cobos, A. Townsend Peterson"
output: 
  github_document:
    toc: yes
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 80
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", 
                      fig.path = "man/figures/README-", out.width = "100%")
```

<!-- badges: start -->

<!-- badges: end -->

<hr>

The package `enmpa` comprises a set of tools to perform Ecological Niche
Modeling using presence-absence data. Some of the main functions help perform
data partitioning, model calibration, model selection, variable response
exploration, and model projection.

<br>

## Installation

You can install the development version of `enmpa` from
[GitHub](https://github.com/Luisagi/enmpa) with:

```{r eval=FALSE}
# install.packages("remotes")
remotes::install_github("Luisagi/enmpa")
```

<br>

## Example

### Loading packages needed

The package `terra` will be used to handle spatial data, and `enmpa` will be
used to perform ENM.

```{r message=FALSE}
library(enmpa)
library(terra)
```

<br>

### Example data

This is a basic example which shows you how to solve a common problem:

```{r message=FALSE, cache=TRUE}
# Load species occurrences and environmental data.
pa_data  <- read.csv(system.file("extdata", "pa_data.csv", package = "enmpa"))
env_vars <- terra::rast(system.file("extdata", "vars.tif", package = "enmpa"))

# Presence-absence data with the values of environmental variables associated
head(pa_data)
```

Check raster layers for the projection area. Obtained from
[WorldClim](https://worldclim.org/):

-   bio_1 = Annual Mean Temperature
-   bio_12 = Annual Precipitation

```{r figures-raster_layers, fig.height=2.5, fig.width=8, cache=TRUE}
terra::plot(env_vars, mar = c(0, 0, 0, 5))
```

<br>

### Model formulas

With `enmpa` you have the possibility to explore multiple model formulas derived
from combinations of variables considering linear (l), quadratic (q), and
product (p) responses. Product refers to pair interactions of variables.

Linear responses:

```{r cache=TRUE}
enmpa::get_formulas(dependent = "Sp", 
                    independent = c("bio_1", "bio_12"),
                    type = "l")
```

Linear + quadratic responses:

```{r cache=TRUE}
enmpa::get_formulas(dependent = "Sp", 
                    independent = c("bio_1", "bio_12"), 
                    type = "lq")
```

Linear + quadratic + products responses:

```{r cache=TRUE}
enmpa::get_formulas(dependent = "Sp", 
                    independent = c("bio_1", "bio_12"), 
                    type = "lqp")
```

<br>

### Model calibration and selection

The function `calibration_glm()` is a wrapper function that allows to:

-   Create model formulas
-   Fit and evaluate models based on such formulas
-   Select best performing models

Model selection consists of three steps:

1.  a first filter to keep the models with ROC AUC \>= 0.5 (statistically
    significant models).
2.  a second filter to maintain only models that meet a `selection_criterion`
    ("TSS": TSS \>= 0.4; or "ESS": maximum Accuracy - tolerance).
3.  from those, pick the ones with delta AIC \<= 2.

<br>

Results are returned as a list containing:

-   selected models `*$selected`
-   a summary of statistics for all models `*$summary`
-   results obtained from cross-validation for all models `*$calibration_results`
-   input data with k-fold partition used `*$data`

<br>

Now lets run an example of model calibration and selection:

```{r cache=TRUE}
# Linear + quadratic + products responses
cal_res <- enmpa::calibration_glm(data = pa_data,
                                  dependent = "Sp",
                                  independent = c("bio_1", "bio_12"),
                                  response_type = "lpq",
                                  selection_criterion = "TSS",
                                  cv_kfolds = 5)
```


Process results:

```{r cache=TRUE}
# Two models were selected out of 31 models evaluated
cal_res$selected
```

<br>

### Predictions (projections)

After one or more models are selected, predictions can be made. In this case we
are projecting the model to the whole area of interest.

```{r warning=FALSE, cache=TRUE, figures-prediction_selected, fig.height=2.5, fig.width=8, cache=TRUE,fig.show="hold"}
# Prediction for the two selected models
preds <- enmpa::predict_selected(x = cal_res, newdata = env_vars, consensus = T)

# Visualization
terra::plot(preds$predictions,  mar = c(0, 0, 0, 5))
```

<br>

### Consensus models

An alternative to strict selection of a single model is to use an ensemble of
models. The main idea is to avoid selecting the best model and instead rely on
multiple candidate models that prove to be robust. 

Here we describe how to create concordance between these models using techniques
such as mean, median or weighted mean based on an information criterion
(Akaike weights).

```{r warning=FALSE, figures-consensus, fig.show="hold", cache=TRUE}
# Consensus projections
terra::plot(preds$consensus, mar=  c(0, 0, 0, 5.1))
```

<br>

### Response Curves

An important step in understanding the ecological niches that can be
characterized with these models is to explore variable responses. The following
lines of code help to do so:

```{r figures-rcurve_model_ID_1, fig.show="hold", out.width="50%", cache=TRUE}
# Response Curves for Bio_1 and Bio_2, first selected model 
enmpa::response_curve(model = preds$fitted_models$Model_ID_1,
                      variable = c("bio_1", "bio_12"),
                      new_data = env_vars)



```

```{r figures-rcurve_model_ID_2, fig.show="hold", out.width="50%", cache=TRUE}
# Response Curves for Bio_1 and Bio_2, second selected model 
enmpa::response_curve(model = preds$fitted_models$Model_ID_2,
                      variable = c("bio_1", "bio_12"),
                      new_data = env_vars)
```

```{r figures-rcurve_consensus, fig.show="hold", out.width="50%", cache=TRUE}
# Consensus Response Curves for Bio_1 and Bio_2, from both models 
enmpa::response_curve(model = preds$fitted_models,
                      variable = c("bio_1", "bio_12"),
                      new_data = env_vars)
```                                                                                                   
  

<br>

### Variable importance

The variable importance or contribution to models can be calculated as a
function of the relative deviance explained by each predictor.

Analysis of Deviance for the first selected model:

```{r warning=FALSE, cache=TRUE}
anova(preds$fitted_models$Model_ID_1, test = "Chi")
```

Using a function from `enmpa` you can explore variable importance in terms of
contribution.

```{r warning=FALSE}
# Relative contribution of the deviance explained for the first model
enmpa::var_importance(preds$fitted_models$Model_ID_1)

```

The function also allows to plot the contributions of the variables for the two
models together which can help with the interpretations:

```{r warning=FALSE}
# Relative contribution of the deviance explained
(vi_both_models <- enmpa::var_importance(preds$fitted_models))
```

```{r warning=FALSE, figures-var_importance, fig.show="hold", out.width="70%", cache=TRUE}
# Plot
enmpa::plot_importance(vi_both_models, extra_info = TRUE)
```

### Final model evaluation 

Finally, we will evaluate the final models using the "independent_eval" function.
Ideally, the model should be validated with an independent data set, but if
unavailable, the entire initial data set used in the calibration process can be
used instead.


```{r}
# Load species occurrences of an indepedent dataset
id_data  <- read.csv(system.file("extdata", "test_data.csv", package = "enmpa"))
head(id_data)
```

#####  Evaluation using presence-absence data.

```{r}
# In this example, we will use the final model calculated as the weighted 
# average of the two selected models.
wmean <- preds$consensus$Weighted_average

eval <- independent_eval(data = id_data, prediction = wmean, occ = "Sp", 
                         crs = "EPSG:4326", xy = c("lon", "lat"))

eval
```


##### Evaluation using presence-only data.

When only presence data is available, the evaluation metrics are based on 
calculating the omission error and using a partial ROC analysis.

To do this we will have to define a threshold value, which will be the minimum 
probability of a presence. We can use any of the three threshold values obtained 
above: ESS, maxTSS or SEN90. 

```{r}
id_data_po <- id_data[id_data$Sp == 1, ] # presence-only data
th <- eval[, "Threshold"][3]             # Threshold based in criteria: SEN90

eval2 <- independent_eval(data = id_data_po, prediction = wmean, occ = "Sp",
                          threshold = th, crs = "EPSG:4326", 
                          xy = c("lon", "lat"))

eval2
```


