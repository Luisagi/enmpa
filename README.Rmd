---
title: "enmpa: Ecological Niche Modeling for Presence-absence Data"
author: "Luis F. Arias-Giraldo, Marlon E. Cobos, A. Townsend Peterson"
output: 
  github_document:
    toc: yes
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 80
link-citations: true
bibliography: references.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", 
                      fig.path = "man/figures/README-", out.width = "100%")
```

<!-- badges: start -->

[![R-CMD-check](https://github.com/Luisagi/enmpa/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Luisagi/enmpa/actions/workflows/R-CMD-check.yaml)

<!-- badges: end -->

<img src="man/figures/enmpa_logo_100dpi.png" align="right" width="166"/></a>

<hr>

## Package description

`enmpa` is an r package that contains a set of tools to perform Ecological Niche
Modeling using presence-absence data. Some of the main functions help perform
data partitioning, model calibration, model selection, variable response
exploration, and model projection.

<br>

<hr>

## Installation

You can install the development version of `enmpa` from
[GitHub](https://github.com/Luisagi/enmpa) with:

```{r eval=FALSE}
# install.packages("remotes")
remotes::install_github("Luisagi/enmpa")
```

<br>

## Packages required

The package `terra` is used to handle spatial data, and `enmpa` is used to
perform ENM.

```{r message=FALSE}
library(enmpa)
library(terra)
```

<br>

## Example data

The data used in this example is included in `enmpa`.

```{r message=FALSE, cache=TRUE}
# Species presence absence data associated with envrionmental variables
data("enm_data", package = "enmpa")

# Data for final model evaluation 
data("test", package = "enmpa")

# Environmental data as raster layers for projections
env_vars <- rast(system.file("extdata", "vars.tif", package = "enmpa"))

# Check the example data
head(enm_data)
```

The raster layers for projections were obtained from
[WorldClim](https://worldclim.org/):

-   bio_1 = Annual Mean Temperature
-   bio_12 = Annual Precipitation

```{r figures-raster_layers, fig.height=2.5, fig.width=8, cache=TRUE}
plot(env_vars, mar = c(1, 1, 2, 4))
```

<br>

## Example

### Detecting signals of ecological niche

To explore the relevance of the variables to be used in niche models, we
implemented in the methods developed by [@cobos2022]. These methods help to
identify signals of ecological niche considering distinct variables and the
presence-absence data. By characterizing the sampling universe, this approach
can determine whether presences and absences can be separated better than
randomly considering distinct environmental factors.

```{r message=FALSE}
sn_bio1  <- niche_signal(data = enm_data, variables = "bio_1", 
                         condition = "Sp", method = "univariate")

sn_bio12 <- niche_signal(data = enm_data, variables = "bio_12",
                         condition = "Sp", method = "univariate")
```

```{r figures-niche_signal, fig.show="hold", out.width="50%", cache=TRUE}
plot_niche_signal(sn_bio1, variables = "bio_1")
plot_niche_signal(sn_bio12, variables = "bio_12")
```

Based on the univariate test results, the variables bio_1 and bio_12 help to
detect signals of ecological niche in our data. In our example, the species
tends to occur in areas with higher annual mean temperatures (bio_1); whereas,
considering annual precipitation (bio_12), the species seems to be present in
areas with lower values. See the function's documentation for more information.

<br>

### Model formulas

With `enmpa` you have the possibility to explore multiple model formulas derived
from combinations of variables considering linear (l), quadratic (q), and
product (p) responses. Product refers to pair interactions of variables.

The function includes the flag `mode` to determine what strategy to use to
combine predictors based on the responses defined in \code{type}. The options of
mode are:

-   **light**.-- returns simple iterations of complex formulas.
-   **moderate**.-- returns a comprehensive number of iterations.
-   **intensive**.-- returns all possible combination. Very time-consuming for 6
    or more independent variables.
-   **complex**.-- returns only the most complex formula.

An example using linear + quadratic responses:

```{r cache=TRUE}
get_formulas(dependent = "Sp", independent = c("bio_1", "bio_12"),  
             type = "lq", mode = "intensive")
```

<br>

### Model calibration and selection

The function `calibration_glm()` is a general function that allows to perform
the following steps:

-   Partition data in k-folds
-   Create formulas for candidate models
-   Fit and evaluate candidate models
-   Select best performing models

Model selection consists of three steps:

1.  A first filter to keep the models with ROC AUC \>= 0.5 (statistically
    significant models).
2.  A second filter to maintain only models that meet a `selection_criterion`
    ("TSS": TSS \>= 0.4; or "ESS": maximum Accuracy - tolerance).
3.  From those, pick the ones with delta AIC \<= 2.

<br>

The results are returned as a list containing:

-   Selected models (`*$selected`)
-   A summary of statistics for all models (`*$summary`)
-   Results obtained from cross-validation for all models
    (`*$calibration_results`)
-   Input data used (`*$data`)
-   The weights used (`*$weights`)
-   The list of partition indices (`*$kfold_index_partition`)

<br>

Now lets run an example of model calibration and selection:

```{r cache=TRUE}
# Linear + quadratic + products responses
cal_res <- calibration_glm(data = enm_data, dependent = "Sp",
                           independent = c("bio_1", "bio_12"),
                           response_type = "lpq", formula_mode = "intensive", 
                           exclude_bimodal = TRUE, selection_criterion = "TSS",
                           cv_kfolds = 5, verbose = FALSE)
```

Process results:

```{r cache=TRUE, paged.print=TRUE}
## Two models were selected out of 31 models evaluated
cal_res$selected[, 1]  # Selected models

cal_res$selected  # Metrics of evaluation
```

<br>

### Fitting and predictions for selected models

After one or more models are selected, the next steps are the fitting and
projection of these models. In this case we are projecting the models to the
whole area of interest.

```{r warning=FALSE, cache=TRUE, figures-prediction_selected, fig.height=2.5,fig.width=8, cache=TRUE,fig.show="hold"}
# Fitting
f_models <- fit_selected(cal_res)

# Prediction for the two selected models and their consensus
preds <- predict_selected(f_models, newdata = env_vars, consensus = TRUE)

# Visualization
plot(preds$predictions, mar = c(1, 1, 2, 4))
```

<br>

### Consensus models

An alternative to strict selection of a single model is to use a consensus
model. The main idea is to avoid selecting the best model and instead rely on
multiple models with similar performance.

During the prediction of selected models, we calculated model consensus using
the mean, median, and a weighted average (using Akaike weights) [@akaike1973;
@wagenmakers2004].

```{r warning=FALSE, figures-consensus, fig.show="hold", cache=TRUE}
# Consensus projections
plot(preds$consensus, mar = c(1, 1, 2, 5))
```

<br>

### Response Curves

An important step in understanding the ecological niches with these models is to
explore variable response curves. The following lines of code help to do so:

```{r figures-rcurve_model_ID_1, fig.show="hold", out.width="50%", cache=TRUE}
# Response Curves for Bio_1 and Bio_2, first selected model 
response_curve(f_models$ModelID_29, variable = "bio_1")

response_curve(f_models$ModelID_29, variable = "bio_12")

```

```{r figures-rcurve_consensus, fig.show="hold", out.width="50%", cache=TRUE}
# Consensus Response Curves for Bio_1 and Bio_2, for both models 
response_curve(f_models, variable = "bio_1")

response_curve(f_models, variable = "bio_12")
```

<br>

### Variable importance

Variable importance or contribution to models can be calculated as a function of
the relative deviance explained by each predictor.

Analysis of Deviance for the first selected model:

```{r warning=FALSE, cache=TRUE}
anova(f_models$ModelID_29, test = "Chi")
```

Using a function from `enmpa` you can also explore variable importance in terms
of contribution.

```{r warning=FALSE}
# Relative contribution of the deviance explained for the first model
var_importance(f_models$ModelID_29)
```

The function also allows to plot the contributions of the variables for the two
models together which can help with the interpretations:

```{r warning=FALSE}
# Relative contribution of the deviance explained
vi_both_models <- var_importance(f_models)
```

```{r warning=FALSE, figures-var_importance, fig.show="hold", out.width="70%", cache=TRUE}
# Plot
plot_importance(vi_both_models, extra_info = TRUE)
```

### Model evaluation with independent data

Finally, we will evaluate the final models using the "independent_eval"
functions. Ideally, the model should be evaluated with an independent data set
(i.e., data that was not used during model calibration or for final model
fitting).

#### Evaluation using presence-absence data.

Using independent data for which presence and absence is known can give the most
robust results. Here an example:

```{r}
# In this example, we will use the final model calculated as the weighted 
# average of the two selected models.
wmean <- preds$consensus$Weighted_average

# check the test data
head(test, 10)

# independent evaluation
eval <- independent_eval01(prediction = wmean, observation = test$Sp, 
                           lon_lat = test[, 2:3])

eval
```

#### Evaluation using presence-only data.

When only presence data is available, the evaluation of performance is based on
the omission error and the partial ROC analysis.

To do this in our example, we will need to define a threshold value. We can use
any of the three threshold values obtained above: ESS, maxTSS or SEN90.

```{r}
# Threshold based in criteria: Sensitivity = 90%
th <- eval[3, "Threshold"]   

# Keep only presence records
test_p <- test[test$Sp == 1,]

# independent evaluation 
eval2 <- independent_eval1(prediction = wmean, threshold = th, 
                           lon_lat = test_p[, 2:3])

eval2
```

### Literature
