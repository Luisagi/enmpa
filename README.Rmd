---
title: "enmpa: Ecological Niche Modeling for Presence-absence Data"
author: "Luis F. Arias-Giraldo, Marlon E. Cobos, A. Townsend Peterson"
output: 
  github_document:
    toc: yes
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 80
link-citations: true
bibliography: references.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", 
                      fig.path = "man/figures/README-", out.width = "100%")
```

<!-- badges: start -->
[![R-CMD-check](https://github.com/Luisagi/enmpa/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Luisagi/enmpa/actions/workflows/R-CMD-check.yaml)
[![CRAN\_Status\_Badge](https://www.r-pkg.org/badges/version/enmpa)](https://cran.r-project.org/package=enmpa)
[![](https://cranlogs.r-pkg.org/badges/grand-total/enmpa)](https://cran.rstudio.com/web/packages/enmpa/index.html)
<!-- badges: end -->

<img src="man/figures/enmpa_logo_100dpi.png" align="right" width="166"/></a>

<hr>

## Package description

`enmpa` is an R package that contains a set of tools to perform Ecological Niche
Modeling using presence-absence data. Some of the main functions help perform
data partitioning, model calibration, model selection, variable response
exploration, and model projection.


##### Citation
If you use `enmpa` in your research, please cite the following paper:

Arias-Giraldo, Luis F., and Marlon E. Cobos. 2024. “enmpa: An R Package for Ecological Niche Modeling Using Presence-Absence Data and Generalized Linear Models”. Biodiversity Informatics 18. https://doi.org/10.17161/bi.v18i.21742.

<br>

<hr>

## Installation

To install the stable version of `enmpa` from CRAN use:

```{r eval=FALSE}
install.packages("enmpa")
```

You can install the development version of `enmpa` from
[GitHub](https://github.com/Luisagi/enmpa) with:

```{r eval=FALSE}
# install.packages("remotes")
remotes::install_github("Luisagi/enmpa")
```

<br>

## Packages required

The package `terra` is used to handle spatial data, and `enmpa` is used to
perform ENM.

```{r message=FALSE}
library(enmpa)
library(terra)
```

```{r echo=FALSE, message=FALSE}
# set terrain default palette
options(terra.pal=terrain.colors(234, rev = TRUE))
```

<br>

## Example data

The data used in this example is included in `enmpa`.

```{r message=FALSE, cache=TRUE}
# Species presence absence data associated with environmental variables
data("enm_data", package = "enmpa")

# Data for final model evaluation 
data("test", package = "enmpa")

# Environmental data as raster layers for projections
env_vars <- rast(system.file("extdata", "vars.tif", package = "enmpa"))

# Check the example data
head(enm_data)
```

The raster layers for projections were obtained from
[WorldClim](https://worldclim.org/):

-   bio_1 = Annual Mean Temperature
-   bio_12 = Annual Precipitation

```{r figures-raster_layers, fig.height=2.5, fig.width=8, cache=TRUE}
plot(env_vars, mar = c(1, 1, 2, 4))
```

<br>

## Example

### Detecting signals of ecological niche

To explore the relevance of the variables to be used in niche models, we
implemented in the methods developed by [@cobos2022]. These methods help to
identify signals of ecological niche considering distinct variables and the
presence-absence data. By characterizing the sampling universe, this approach
can determine whether presences and absences can be separated better than
randomly considering distinct environmental factors.

```{r message=FALSE}
sn_bio1  <- niche_signal(data = enm_data, variables = "bio_1", 
                         condition = "Sp", method = "univariate")

sn_bio12 <- niche_signal(data = enm_data, variables = "bio_12",
                         condition = "Sp", method = "univariate")
```

```{r figures-niche_signal, fig.show="hold", out.width="50%", cache=TRUE}
plot_niche_signal(sn_bio1, variables = "bio_1")
plot_niche_signal(sn_bio12, variables = "bio_12")
```

Based on the univariate test results, the variables bio_1 and bio_12 help to
detect signals of ecological niche in our data. In our example, the species
tends to occur in areas with higher annual mean temperatures (bio_1); whereas,
considering annual precipitation (bio_12), the species seems to be present in
areas with lower values. See the function's documentation for more information.

<br>

### Model formulas

With `enmpa` you have the possibility to explore multiple model formulas derived
from combinations of variables considering linear (l), quadratic (q), and
product (p) responses. Product refers to pair interactions of variables.

The function includes the flag `mode` to determine what strategy to use to
combine predictors based on the responses defined in \code{type}. The options of
mode are:

-   **light**.-- returns simple iterations of complex formulas.
-   **moderate**.-- returns a comprehensive number of iterations.
-   **intensive**.-- returns all possible combination. Very time-consuming for 6
    or more independent variables.
-   **complex**.-- returns only the most complex formula.

An example using linear + quadratic responses:

```{r cache=TRUE}
get_formulas(dependent = "Sp", independent = c("bio_1", "bio_12"),  
             type = "lq", mode = "intensive")
```

<br>

### Model calibration and selection

The function `calibration_glm()` is a general function that allows to perform
the following steps:

-   Partition data in k-folds
-   Create formulas for candidate models
-   Fit and evaluate candidate models
-   Select best performing models

Model selection consists of three steps:

1.  A first filter to keep the models with ROC AUC \>= 0.5 (statistically
    significant models).
2.  A second filter to maintain only models that meet a `selection_criterion`
    ("TSS": TSS \>= 0.4; or "ESS": maximum Accuracy - tolerance).
3.  From those, pick the ones with delta AIC \<= 2.

<br>

The results are returned as a list containing:

-   Selected models (`*$selected`)
-   A summary of statistics for all models (`*$summary`)
-   Results obtained from cross-validation for all models
    (`*$calibration_results`)
-   Input data used (`*$data`)
-   The weights used (`*$weights`)
-   The list of partition indices (`*$kfold_index_partition`)

<br>

Now lets run an example of model calibration and selection:

```{r cache=TRUE}
# Linear + quadratic + products responses
calibration <- calibration_glm(data = enm_data, dependent = "Sp",
                               independent = c("bio_1", "bio_12"),
                               response_type = "lpq",
                               formula_mode = "intensive", 
                               exclude_bimodal = TRUE, 
                               selection_criterion = "TSS",
                               cv_kfolds = 5, verbose = FALSE)
calibration
```

Process results:

```{r cache=TRUE, paged.print=TRUE}
## Summary of the calibration
summary(calibration)
```


<br>

### Fitting and predictions for selected models

After one or more models are selected, the next steps are the fitting and
projection of these models. In this case we are projecting the models to the
whole area of interest. Models can be transferred with three options: 
free extrapolation ('E'), extrapolation with clamping ('EC'), and 
no extrapolation ('NE').

```{r warning=FALSE, cache=TRUE, figures-prediction_selected, cache=TRUE,fig.show="hold"}
# Fitting selected models
fits <- fit_selected(calibration)

# Prediction for the two selected models and their consensus
preds_E  <- predict_selected(fits, newdata = env_vars, extrapolation_type = "E",
                             consensus = TRUE)
preds_NE <- predict_selected(fits, newdata = env_vars,extrapolation_type = "NE",
                             consensus = TRUE)

# Visualization
plot(c(preds_E$predictions, preds_NE$predictions),
     main = c("Model ID 29 (E)", "Model ID 31 (E)",
              "Model ID 29 (NE)", "Model ID 31 (NE)"),
     mar = c(1, 1, 2, 5))
```

<br>

### Consensus models

An alternative to strict selection of a single model is to use a consensus
model. The main idea is to avoid selecting the best model and instead rely on
multiple models with similar performance.

During the prediction of selected models, we calculated model consensus using
the mean, median, and a weighted average (using Akaike weights) [@akaike1973;
@wagenmakers2004].

```{r warning=FALSE, figures-consensus, fig.show="hold", cache=TRUE}
# Consensus projections
plot(preds_E$consensus, mar = c(1, 1, 2, 5))
```

<br>

### Response Curves

An important step in understanding the ecological niches with these models is to
explore variable response curves. The following lines of code help to do so:

```{r figures-rcurve_model_ID_1, fig.show="hold", out.width="50%", cache=TRUE}
# Response Curves for Bio_1 and Bio_2, first selected model 
response_curve(fitted = fits, modelID = "ModelID_29", variable = "bio_1")
response_curve(fitted = fits, modelID = "ModelID_29", variable = "bio_12")
```

```{r figures-rcurve_consensus, fig.show="hold", out.width="50%", cache=TRUE}
# Consensus Response Curves for Bio_1 and Bio_2, for both models 
response_curve(fits, variable = "bio_1")
response_curve(fits, variable = "bio_12")
```

### Two-way interactions

It is useful to examine whether the effect of one variable depends on the level
of other variables. If it does, then we have what is called an 'interaction'.
According to the calibration results from this example, in both models, the
predictor `bio_1:bio_12` was selected. To explore the interaction of these two
variables, the function `resp2var` can help us to visualize this interaction.

```{r figures-rcurve_two, fig.show="hold", out.width="50%", cache=TRUE}
# Consensus Response Curves for Bio_1 and Bio_2, for both models
resp2var(model = fits,
         modelID = "ModelID_29",
         main = "ModelID 29",
         variable1 = "bio_1",
         variable2 = "bio_12",
         extrapolate = TRUE,
         add_limits = TRUE)

resp2var(model = fits,
         modelID = "ModelID_31",
         main = "ModelID 31",
         variable1 = "bio_1",
         variable2 = "bio_12",
         extrapolate = TRUE,
         add_limits = TRUE)
```

<br>

### Variable importance

Variable importance or contribution to models can be calculated as a function of
the relative deviance explained by each predictor.

Analysis of Deviance for the first selected model:

```{r warning=FALSE, cache=TRUE}
anova(fits$glms_fitted$ModelID_29, test = "Chi")
```

Using a function from `enmpa` you can also explore variable importance in terms
of contribution.

```{r warning=FALSE}
# Relative contribution of the deviance explained for the first model
var_importance(fitted = fits, modelID = "ModelID_29")
```

The function also allows to plot the contributions of the variables for the two
models together which can help with the interpretations:

```{r warning=FALSE}
# Relative contribution of the deviance explained
vi_both_models <- var_importance(fits)
```

```{r warning=FALSE, figures-var_importance, fig.show="hold", out.width="70%", cache=TRUE}
# Plot
plot_importance(vi_both_models, extra_info = TRUE)
```

The Jackknife function providing a detailed reflection of the impact of each
variable on the overall model, considering four difference measures: ROC-AUC,
TSS, AICc, and Deviance.

```{r warning=FALSE}
# Jackknife test
jk <- jackknife(data = enm_data,
          dependent = "Sp",
          independent = c("bio_1", "bio_12"),
          response_type = "lpq")

jk
```

```{r warning=FALSE, cache=TRUE, figures-jackk, fig.show="hold", fig.height=4, fig.width=7.5,out.width="50%"}
# Jackknife plots
plot_jk(jk, metric = "TSS")
plot_jk(jk, metric = "AIC")
plot_jk(jk, metric = "ROC_AUC")
plot_jk(jk, metric = "Residual_deviance")
```


### Final model evaluation with independent data

Finally, we will evaluate the final models using the "independent_eval"
functions. Ideally, the model should be evaluated with an independent data set
(i.e., data that was not used during model calibration or for final model
fitting).

```{r}
# Loading an independent dataset
data("test", package = "enmpa")

# The independent evaluation data are divided into two groups: 
# presences-absences (test_01) and presences-only (test_1).
test_1  <- test[test$Sp == 1,]
test_01 <- test

head(test_1)
head(test_01)
```

#### Using presence-absence data.

Using independent data for which presence and absence is known can give the most
robust results. Here an example:

```{r}
projections <- list(
  ModelID_29 = preds_E$predictions$ModelID_29,
  ModelID_31 = preds_E$predictions$ModelID_31,
  Consensus_WA = preds_E$consensus$Weighted_average
)

ie_01 <- lapply(projections, function(x){
  independent_eval01(prediction = x,
                     observation = test_01$Sp,
                     lon_lat = test_01[, c("lon", "lat")])
})

ie_01
```

#### Evaluation using presence-only data.

When only presence data is available, the evaluation of performance is based on
the omission error and the partial ROC analysis.

To do this in our example, we will need to define a threshold value. We can use
any of the three threshold values obtained above: ESS, maxTSS or SEN90.

```{r}
# In this example, we will use the weighted average of the two selected models.

# Consensus_WA
Consensus_WA_T1 <- ie_01[["Consensus_WA"]][1, "Threshold"] # ESS
Consensus_WA_T2 <- ie_01[["Consensus_WA"]][2, "Threshold"] # maxTSS
Consensus_WA_T3 <- ie_01[["Consensus_WA"]][3, "Threshold"] # SEN90

aux_list <- list(ESS = Consensus_WA_T1, maxTSS = Consensus_WA_T2,
                  SEN90 = Consensus_WA_T3)

lapply(aux_list, function(th){
  independent_eval1(prediction = projections[["Consensus_WA"]],
                    threshold = th,
                    lon_lat = test_1[, c("lon", "lat")])
  
})

```

### Literature
